# include the application.conf at the top
include required(classpath("application"))

system.delete-workflow-files = true
system.file-hash-cache = true

backend {
  default = "Slurm"

  providers {
	Slurm {
  		actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"
  		config {
    			runtime-attributes = """
    			Int runtime_minutes = 10080
    			Int cpus = 8
    			Int requested_memory = 16000
    			String queue = "general"
    			"""

    			submit = """
        		sbatch -J ${job_name} -D ${cwd} -o ${out} -e ${err} -t ${runtime_minutes} -p ${queue} \
        		${"-c " + cpus} \
        		--mem=${requested_memory} \
        		--wrap "/bin/bash ${script}"
    			"""

    			kill = "scancel ${job_id}"
    			check-alive = "squeue -j ${job_id}"
    			job-id-regex = "Submitted batch job (\\d+).*"

  		
			filesystems {
 				local {
   					localization: [
     						"soft-link", "hard-link", "copy"
   					]

            		## call caching config relating to the filesystem side
            		caching {
              			# When copying a cached result, what type of file duplication should occur. Attempted in the order listed below:
              			duplication-strategy: [
                			"soft-link"
              			]
              			hashing-strategy: "path+modtime"
              			# Possible values: file, path, path+modtime
              			# "file" will compute an md5 hash of the file content.
              			# "path" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to "soft-link",
             		 	# in order to allow for the original file path to be hashed.

              			check-sibling-md5: false
              			# When true, will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash.
              			# If false or the md5 does not exist, will proceed with the above-defined hashing strategy.
					}
            	}
			}
		}
	}
  }
}

# Optional call-caching configuration.
call-caching {
  # Allows re-use of existing results for jobs you've already run
  # (default: false)
  enabled = true

  # Whether to invalidate a cache result forever if we cannot reuse them. Disable this if you expect some cache copies
  # to fail for external reasons which should not invalidate the cache (e.g. auth differences between users):
  # (default: true)
  invalidate-bad-cache-results = true

  # The maximum number of times Cromwell will attempt to copy cache hits before giving up and running the job.
  #max-failed-copy-attempts = 1000000

}

database {
  # mysql example
  #driver = "slick.driver.MySQLDriver$" #old way

  profile = "slick.jdbc.MySQLProfile$"


  # see all possible parameters and default values here:
  # http://slick.lightbend.com/doc/3.2.0/api/index.html#slick.jdbc.JdbcBackend$DatabaseFactoryDef@forConfig(String,Config,Driver):Database
  # https://dev.mysql.com/doc/connector-j/8.0/en/connector-j-reference-jdbc-url-format.html

  db {
    driver = "com.mysql.cj.jdbc.Driver"
    url = "jdbc:mysql://chdgenes.org/cromwell?rewriteBatchedStatements=true&useSSL=false"
    user = "cromwell"
    password = "L3kK1ds2018"
    connectionTimeout = 5000
  }

  # For batch inserts the number of inserts to send to the DB at a time
  insert-batch-size = 2000

}
